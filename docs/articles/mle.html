<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="VisualStats">
<title>Visual Introduction to Maximum Likelihood Estimation • VisualStats</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Visual Introduction to Maximum Likelihood Estimation">
<meta property="og:description" content="VisualStats">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">VisualStats</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/anova.html">Graphical Analysis of Variance</a>
    <a class="dropdown-item" href="../articles/loess.html">Loess Regression</a>
    <a class="dropdown-item" href="../articles/log_likelihood.html">The Path to Log Likelihood</a>
    <a class="dropdown-item" href="../articles/mle.html">Visual Introduction to Maximum Likelihood Estimation</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jbryer/VisualStats/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="mle_files/htmlwidgets-1.5.4/htmlwidgets.js"></script><link href="mle_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="mle_files/datatables-binding-0.21/datatables.js"></script><link href="mle_files/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="mle_files/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="mle_files/dt-core-1.11.3/js/jquery.dataTables.min.js"></script><link href="mle_files/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="mle_files/crosstalk-1.2.0/js/crosstalk.min.js"></script><div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Visual Introduction to Maximum Likelihood Estimation</h1>
                        <h4 data-toc-skip class="author">Jason Bryer, Ph.D.</h4>
            
            <h4 data-toc-skip class="date">2022-03-01</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jbryer/VisualStats/blob/HEAD/vignettes/mle.Rmd" class="external-link"><code>vignettes/mle.Rmd</code></a></small>
      <div class="d-none name"><code>mle.Rmd</code></div>
    </div>

    
    
<p><a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" class="external-link">Maximum Likelihood Estimation</a> (MLE) is an important procedure for estimating parameters in statistical models. It is often first encountered when modeling a dichotomous outcome variable vis-à-vis logistic regression. However, it is the backbone of <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" class="external-link">generalized linear models</a> (GLM) which allow for error distribution models other than the normal distribution. Most introductions to MLE rely on mathematical notation that for many students is opaque and hinders learning how this method works. The document outlines an approach to understanding MLE that relies on visualizations and mathematical notation is only used when necessary.</p>
<p>We will begin with a typical bivariate regression using the <code>mtcars</code> data set where we wish to predict <code>mpg</code> (miles per gallon) from <code>wt</code> (weight in 1,000 lbs). Figure 1 is a scatter plot showing the relationship between these two variables.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-1-1.png" alt="Figure 1. Scatter plot of weight versus miles per gallan." width="700"><p class="caption">
Figure 1. Scatter plot of weight versus miles per gallan.
</p>
</div>
<p>Our goal is to estimate</p>
<p><span class="math display">\[Y_{mpg} = \beta_{wt} X + e\]</span> where <span class="math inline">\(\beta_{wt}\)</span> is the slope and <span class="math inline">\(e\)</span> is the intercept.</p>
<div class="section level2">
<h2 id="ordinary-least-squares">Ordinary Least Squares<a class="anchor" aria-label="anchor" href="#ordinary-least-squares"></a>
</h2>
<p>With ordinary least squares (OLS) regression our goal is to minimize the residual sum of squares (RSS):</p>
<p><span class="math display">\[RSS=\sum^{n}_{i=1} \left( y_{i}-f(x_{i})\right)^{2}\]</span></p>
<p>where <span class="math inline">\(y_i\)</span> is the variable to be predicted, <span class="math inline">\(f(x_i)\)</span> is the predicted value of <span class="math inline">\(y_i\)</span>, and <span class="math inline">\(n\)</span> is the sample size. Figure 2 superimposes the residuals on the scatter plot. By squaring the length of each of those lines we accomplish two things: 1) we make all the values to be summed positive (i.e. a line that fits all the data perfectly will have a RSS = 0) and 2) points that fall further from the regression line contribute more (geometrically more) to the RSS then points close to the regression line.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-2-1.png" alt="Figure 2 Scatter plot with residuals." width="700"><p class="caption">
Figure 2 Scatter plot with residuals.
</p>
</div>
<p>The basic properties we know about regression are:</p>
<ul>
<li>The correlation measures the strength of the relationship between x and y (see <a href="https://shiny.rit.albany.edu/stat/rectangles/" class="external-link">this shiny app</a> for an excellent visual overview of correlations).</li>
<li>The correlation ranges between -1 and 1.</li>
<li>The mean of x and y must fall on the line.</li>
<li>The slope of a line is defined as the change in y over the change in x (<span class="math inline">\(\frac{\Delta y}{\Delta x}\)</span>). For regression use the ration of the standard deviations such that the correlation is defined as <span class="math inline">\(m = r \frac{s_y}{s_x}\)</span> where <span class="math inline">\(m\)</span> is the slope, <span class="math inline">\(r\)</span> is the correlation, and <span class="math inline">\(s\)</span> is the sample standard deviation.</li>
</ul>
<p>We can easily calculate the RSS for various correlations (<span class="math inline">\(r\)</span>) ranging between -1 and 1. Figure 3 visualizes the RSS.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>
<span class="va">mean.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="va">mean.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">sd.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="va">sd.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">ols</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>
    r <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">0.025</span><span class="op">)</span>,            <span class="co"># Correlation</span>
    m <span class="op">=</span> <span class="va">r</span> <span class="op">*</span> <span class="op">(</span><span class="va">sd.y</span> <span class="op">/</span> <span class="va">sd.x</span><span class="op">)</span>,                 <span class="co"># Slope</span>
    b <span class="op">=</span> <span class="va">mean.y</span> <span class="op">-</span> <span class="va">m</span> <span class="op">*</span> <span class="va">mean.x</span>                <span class="co"># Intercept</span>
<span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">rowwise</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">mutate</span><span class="op">(</span>ss <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="va">m</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">b</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="co"># Sum of squares residuals</span>
    <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu">datatable</span><span class="op">(</span><span class="va">ols</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">formatRound</span><span class="op">(</span>columns <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">ols</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></code></pre></div>
<div id="htmlwidget-852f153ef9f44653221c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-852f153ef9f44653221c">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81"],[-1,-0.975,-0.95,-0.925,-0.9,-0.875,-0.85,-0.825,-0.8,-0.775,-0.75,-0.725,-0.7,-0.675,-0.65,-0.625,-0.6,-0.575,-0.55,-0.525,-0.5,-0.475,-0.45,-0.425,-0.4,-0.375,-0.35,-0.325,-0.3,-0.275,-0.25,-0.225,-0.2,-0.175,-0.15,-0.125,-0.1,-0.075,-0.0499999999999999,-0.0249999999999999,0,0.0250000000000001,0.05,0.075,0.1,0.125,0.15,0.175,0.2,0.225,0.25,0.275,0.3,0.325,0.35,0.375,0.4,0.425,0.45,0.475,0.5,0.525,0.55,0.575,0.6,0.625,0.65,0.675,0.7,0.725,0.75,0.775,0.8,0.825,0.85,0.875,0.9,0.925,0.95,0.975,1],[-6.15964250184826,-6.00565143930205,-5.85166037675585,-5.69766931420964,-5.54367825166343,-5.38968718911723,-5.23569612657102,-5.08170506402481,-4.92771400147861,-4.7737229389324,-4.61973187638619,-4.46574081383999,-4.31174975129378,-4.15775868874757,-4.00376762620137,-3.84977656365516,-3.69578550110895,-3.54179443856275,-3.38780337601654,-3.23381231347033,-3.07982125092413,-2.92583018837792,-2.77183912583172,-2.61784806328551,-2.4638570007393,-2.3098659381931,-2.15587487564689,-2.00188381310068,-1.84789275055448,-1.69390168800827,-1.53991062546206,-1.38591956291586,-1.23192850036965,-1.07793743782344,-0.923946375277238,-0.769955312731032,-0.615964250184826,-0.461973187638619,-0.307982125092412,-0.153991062546206,0,0.153991062546207,0.307982125092413,0.461973187638619,0.615964250184826,0.769955312731032,0.92394637527724,1.07793743782345,1.23192850036965,1.38591956291586,1.53991062546206,1.69390168800827,1.84789275055448,2.00188381310068,2.15587487564689,2.3098659381931,2.4638570007393,2.61784806328551,2.77183912583172,2.92583018837792,3.07982125092413,3.23381231347034,3.38780337601654,3.54179443856275,3.69578550110896,3.84977656365516,4.00376762620137,4.15775868874757,4.31174975129378,4.46574081383999,4.61973187638619,4.7737229389324,4.92771400147861,5.08170506402481,5.23569612657102,5.38968718911723,5.54367825166343,5.69766931420964,5.85166037675585,6.00565143930205,6.15964250184826],[39.9077348390713,39.4123070930945,38.9168793471177,38.421451601141,37.9260238551642,37.4305961091874,36.9351683632106,36.4397406172338,35.944312871257,35.4488851252803,34.9534573793035,34.4580296333267,33.9626018873499,33.4671741413731,32.9717463953964,32.4763186494196,31.9808909034428,31.485463157466,30.9900354114892,30.4946076655124,29.9991799195357,29.5037521735589,29.0083244275821,28.5128966816053,28.0174689356285,27.5220411896517,27.026613443675,26.5311856976982,26.0357579517214,25.5403302057446,25.0449024597678,24.549474713791,24.0540469678143,23.5586192218375,23.0631914758607,22.5677637298839,22.0723359839071,21.5769082379303,21.0814804919536,20.5860527459768,20.090625,19.5951972540232,19.0997695080464,18.6043417620697,18.1089140160929,17.6134862701161,17.1180585241393,16.6226307781625,16.1272030321857,15.631775286209,15.1363475402322,14.6409197942554,14.1454920482786,13.6500643023018,13.154636556325,12.6592088103483,12.1637810643715,11.6683533183947,11.1729255724179,10.6774978264411,10.1820700804643,9.68664233448756,9.19121458851078,8.69578684253399,8.20035909655721,7.70493135058043,7.20950360460365,6.71407585862687,6.21864811265008,5.7232203666733,5.22779262069652,4.73236487471973,4.23693712874295,3.74150938276616,3.24608163678939,2.75065389081261,2.25522614483582,1.75979839885904,1.26437065288225,0.768942906905473,0.273515160928692],[298.043573729544,291.296263878493,285.956513011817,282.024321129516,279.49968823159,278.382614318038,278.673099388862,280.371143444061,283.476746483635,287.989908507584,293.910629515908,301.238909508607,309.974748485681,320.11814644713,331.669103392954,344.627619323152,358.993694237726,374.767328136675,391.948521019999,410.537272887698,430.533583739772,451.937453576221,474.748882397045,498.967870202244,524.594416991818,551.628522765766,580.07018752409,609.919411266789,641.176193993863,673.840535705312,707.912436401136,743.391896081335,780.278914745909,818.573492394858,858.275629028181,899.38532464588,941.902579247954,985.827392834403,1031.15976540523,1077.89969696043,1126.0471875,1175.60223702395,1226.56484553227,1278.93501302497,1332.71273950205,1387.89802496349,1444.49086940932,1502.49127283952,1561.89923525409,1622.71475665304,1684.93783703636,1748.56847640406,1813.60667475614,1880.05243209259,1947.90574841341,2017.16662371861,2087.83505800818,2159.91105128213,2233.39460354046,2308.28571478315,2384.58438501023,2462.29061422168,2541.4044024175,2621.9257495977,2703.85465576227,2787.19112091122,2871.93514504455,2958.08672816224,3045.64587026432,3134.61257135077,3224.98683142159,3316.76865047679,3409.95802851637,3504.55496554031,3600.55946154864,3697.97151654134,3796.79113051841,3897.01830347986,3998.65303542568,4101.69532635588,4206.14517627046]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>r<\/th>\n      <th>m<\/th>\n      <th>b<\/th>\n      <th>ss<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\", null);\n  }"},{"targets":3,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 3, 3, \",\", \".\", null);\n  }"},{"className":"dt-right","targets":[1,2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render","options.columnDefs.3.render"],"jsHooks":[]}</script><div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-4-1.png" alt="Figure 3. Residual sum of squares." width="700"><p class="caption">
Figure 3. Residual sum of squares.
</p>
</div>
<p>The correlation with the correlation the resulted in the smallest RSS is -0.875.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ols</span> <span class="op">%&gt;%</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">ss</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">ss</span><span class="op">)</span><span class="op">)</span> <span class="co"># Select the row with the smallest sum of squares residuals</span></code></pre></div>
<pre><code><span class="co">##        r         m       b       ss</span>
<span class="co">## 1 -0.875 -5.389687 37.4306 278.3826</span></code></pre>
<p>Calculating the correlation in R gives us -0.8676594 and the slope is -5.3444716 which is close to our estimate here. We could get a more accurate result if we tried smaller steps in the correlation (see the <code>by</code> parameter in the <code>seq</code> function above).</p>
</div>
<div class="section level2">
<h2 id="minimizing-rss-algorithmically">Minimizing RSS Algorithmically<a class="anchor" aria-label="anchor" href="#minimizing-rss-algorithmically"></a>
</h2>
<p>This approach works well here because the correlation is bounded between -1 and 1 and we can easily calculate the RSS for a bunch of possible correlations. However, there are more efficient ways of finding the correlation that minimizes the RSS than trying correlations equally distributed across the possible range. For example, consider the following simple algorithm:</p>
<ol style="list-style-type: decimal">
<li>Calculate the RSS for <span class="math inline">\(r = 0\)</span>.</li>
<li>Calculate the RSS for <span class="math inline">\(r = 0.5\)</span> If <span class="math inline">\(RSS_{0.5} &lt; RSS_{0}\)</span> then calculate the RSS with <span class="math inline">\(r = 0.75\)</span>, else calculate the RSS with <span class="math inline">\(r = -0.5%\)</span>
</li>
</ol>
<p>We can repeat this procedure, essentially halving the distance in each iteration until we find a sufficiently small RSS. This process is, in essence, the idea of numerical optimization procedures. In R, the <code>optim</code> function implements the <a href="https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method" class="external-link">Nedler-Mead</a> (Nedler &amp; Mead, 1965) and <a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS" class="external-link">Limited Memory BFGS</a> (Byrd et al, 1995) methods for optimizing a set of parameters. The former is the default but we will use the latter throughout this document since it allows for specifying bounds for certain parameters (e.g. only consider positive values). The details of <em>how</em> the algorithm works is beyond the scope of this article (see this <a href="https://www.benfrederickson.com/numerical-optimization/" class="external-link">interactive tutoral</a> by Ben Frederickson for a good introduction), instead we will focus on <em>what</em> the algorithm does. To begin, we must define a function that calculates a metric for which the optimizer is going to minimize (or maximize). Let’s start with RSS:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">residual_sum_squares</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">parameters</span>, <span class="va">predictor</span>, <span class="va">outcome</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">a</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="co"># Intercept</span>
    <span class="va">b</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="co"># beta coefficient</span>
    <span class="va">predicted</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span> <span class="op">*</span> <span class="va">predictor</span>
    <span class="va">residuals</span> <span class="op">&lt;-</span> <span class="va">outcome</span> <span class="op">-</span> <span class="va">predicted</span>
    <span class="va">ss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">residuals</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">ss</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>The <code>parameters</code> is a vector of the parameters the algorithm is going to minimize (or maximize). Here, these will be the slope and intercept. The <code>predictor</code> and <code>outcome</code> are parameters passed through from the <code>...</code> parameter on the <code>optim</code> function and are necessary for us to calculate the RSS. We can now get the RSS for any set of parameters.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">residual_sum_squares</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">37</span>, <span class="op">-</span><span class="fl">5</span><span class="op">)</span>, <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>, <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span><span class="op">)</span></code></pre></div>
<pre><code><span class="co">## [1] 303.5247</span></code></pre>
<p><strong>Small Digression</strong> In order to explore each step of the algorithm, we need to wrap the <code>optim</code> function to capture the parameters and output of the function. The <code>optim_save</code><a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;This function is available in the &lt;code&gt;VisualStats&lt;/code&gt; package.&lt;/p&gt;"><sup>1</sup></a> function will add two elements to the returned list: <code>iterations</code> is the raw list of the parameters and output saved and <code>iterations_df</code> is a <code>data.frame</code> containing the same data.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim_save</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">fn</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">iterations</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>
    <span class="va">wrap_fun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">parameters</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
        <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">iterations</span><span class="op">)</span>
        <span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">fn</span><span class="op">(</span><span class="va">parameters</span>, <span class="va">...</span><span class="op">)</span>
        <span class="va">iterations</span><span class="op">[[</span><span class="va">n</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">parameters</span>, <span class="va">result</span><span class="op">)</span>
        <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span>
    <span class="op">}</span>
    <span class="va">optim_out</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/optim.html" class="external-link">optim</a></span><span class="op">(</span><span class="va">par</span>, <span class="va">wrap_fun</span>, <span class="va">...</span><span class="op">)</span>
    <span class="va">optim_out</span><span class="op">$</span><span class="va">iterations</span> <span class="op">&lt;-</span> <span class="va">iterations</span>
    <span class="va">optim_out</span><span class="op">$</span><span class="va">iterations_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="va">iterations</span><span class="op">)</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">optim_out</span><span class="op">$</span><span class="va">iterations_df</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">'Param'</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">par</span><span class="op">)</span><span class="op">)</span>, <span class="st">'Result'</span><span class="op">)</span>
    <span class="va">optim_out</span><span class="op">$</span><span class="va">iterations_df</span><span class="op">$</span><span class="va">Iteration</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">optim_out</span><span class="op">$</span><span class="va">iterations_df</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">optim_out</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>We can now call the <code>optim_save</code> function with our <code>residual_sum_squares</code> function. We initialize the algorithm with two random values for the intercept and slope, respectively. Note that we are using Broyden, Fletcher, Goldfarb, and Shanno optimization method which allows for the specification of bounds on the parameter estimates which we will use later.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.rss</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optim_save.html">optim_save</a></span><span class="op">(</span>
    par <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,
    fn <span class="op">=</span> <span class="va">residual_sum_squares</span>, 
    method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,
    predictor <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>,
    outcome <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>
<span class="op">)</span></code></pre></div>
<p>The <code>par</code> parameter provides the final parameter estimates.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.rss</span><span class="op">$</span><span class="va">par</span></code></pre></div>
<pre><code><span class="co">## [1] 37.285116 -5.344469</span></code></pre>
<p>We can see that the parameters are accurate to at least four decimal places to the OLS method used by the <code>lm</code> function.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm.out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">mpg</span> <span class="op">~</span> <span class="va">wt</span>, data <span class="op">=</span> <span class="va">mtcars</span><span class="op">)</span>
<span class="va">lm.out</span><span class="op">$</span><span class="va">coefficients</span></code></pre></div>
<pre><code><span class="co">## (Intercept)          wt </span>
<span class="co">##   37.285126   -5.344472</span></code></pre>
<p>It took the <code>optim</code> function 65 iterations to find the optimal set of parameters that minimized the RSS. Figure 4 shows the value of the parameters (i.e. intercept and slope) and the RSS for each iteration.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">optim.rss</span><span class="op">$</span><span class="va">iterations_df</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'Intercept'</span>, <span class="st">'Slope'</span>, <span class="st">'ResidualSumSquares'</span>, <span class="st">'Iteration'</span><span class="op">)</span>
<span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu">melt</span><span class="op">(</span>id.var <span class="op">=</span> <span class="st">'Iteration'</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Iteration</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">variable</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fu">geom_path</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">variable</span>, scales <span class="op">=</span> <span class="st">"free_y"</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">xlab</span><span class="op">(</span><span class="st">'Iteration'</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ylab</span><span class="op">(</span><span class="st">''</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">'none'</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-12-1.png" alt="Figure 4. Output of the optimizaiton procedure at each iteration." width="700"><p class="caption">
Figure 4. Output of the optimizaiton procedure at each iteration.
</p>
</div>
</div>
<div class="section level2">
<h2 id="likelihood">Likelihood<a class="anchor" aria-label="anchor" href="#likelihood"></a>
</h2>
<p>Now that we have laid the groundwork for finding parameters algorithmically, we need to introduce another way of evaluating how well parameters <em>fit</em> the data, namely the likelihood. First, let’s revisit what we are doing in OLS. Figure 5 is a scatter plot of our observations, the OLS regression line in blue, and one observation highlighted in red with the residual as a red line. With OLS, we square the residual for every observation, thereby making all values positive, and summing them. There is, however, another way of estimating fit that doesn’t rely on the residuals.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-13-1.png" alt="Figure 5. Scatter plot with residuals for one observation." width="700"><p class="caption">
Figure 5. Scatter plot with residuals for one observation.
</p>
</div>
<p>We often think of probabilities as the areas under a fixed distribution. For example, the first car in <code>mtcars</code> is Mazda RX4 with an average miles per gallon of 21 and weighs 2620lbs. The probability of a car with a miles per gallon less than Mazda RX4 given the data we have in <code>mtcars</code> is 0.5599667 and is depicted in Figure 6.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-14-1.png" alt="Figure 6. Probability distribution of miles per gallan." width="700"><p class="caption">
Figure 6. Probability distribution of miles per gallan.
</p>
</div>
<p>For probabilities, we are working with a fixed distribution, that is:</p>
<p><span class="math display">\[pr(data\ |\ distribution)\]</span> The likelihood are the y-axis values (i.e. density) for fixed data points with distributions that can move, that is:</p>
<p><span class="math display">\[L(distribution\ |\ data)\]</span> The likelihood is the height of the density function. Figure 7 depicts two likelihood for two observations. The mean of each distribution is equal to <span class="math inline">\(\beta_{wt} X + e\)</span> and the intercept (also known as the error term) defines the standard deviation of the distribution.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-15-1.png" alt="Figure 7. Likelihood of a car having the observed mpg given the model parameters for two observations." width="700"><p class="caption">
Figure 7. Likelihood of a car having the observed mpg given the model parameters for two observations.
</p>
</div>
<p>We can then calculate the likelihood for each observation in our data. Unlike OLS, we now want to <em>maximize</em> the sum of these values. Also, we are going to use the log of the likelihood so we can add them instead of multiplying. We can now define our log likelihood function:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">loglikelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">parameters</span>, <span class="va">predictor</span>, <span class="va">outcome</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">a</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>     <span class="co"># intercept</span>
    <span class="va">b</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>     <span class="co"># slope / beta coefficient</span>
    <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="co"># error</span>
    <span class="va">ll.vec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">outcome</span>, <span class="va">a</span> <span class="op">+</span> <span class="va">b</span> <span class="op">*</span> <span class="va">predictor</span>, <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">ll.vec</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Note that we have to estimate a third parameter, sigma, which is the error term and defines the standard deviation for the normal distribution for estimating the likelihood. This is connected to the distribution of the residuals as we will see later. We can now calculate the log-likelihood for any combination of parameters.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">loglikelihood</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">37</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span><span class="op">)</span><span class="op">)</span>,
              predictor <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>,
              outcome <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span><span class="op">)</span></code></pre></div>
<pre><code><span class="co">## [1] -91.06374</span></code></pre>
</div>
<div class="section level2">
<h2 id="maximum-likelihood-estimation">Maximum Likelihood Estimation<a class="anchor" aria-label="anchor" href="#maximum-likelihood-estimation"></a>
</h2>
<p>We can now use the <code>optim_save</code> function to find the parameters that <em>maximize</em> the log-likelihood. Note two important parameter changes:</p>
<ol style="list-style-type: decimal">
<li>We are specifying the <code>lower</code> parameter so that the algorithm will not try negative values for sigma since the variance cannot be negative.</li>
<li>The value for the <code>control</code> parameter indicates that we wish to maximize the values instead of minimizing (which is the default).</li>
</ol>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.ll</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optim_save.html">optim_save</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>,                     <span class="co"># Random initial values</span>
    <span class="va">loglikelihood</span>,                <span class="co"># Log-likelihood function</span>
    lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="op">-</span><span class="cn">Inf</span>, <span class="fl">1.e-5</span><span class="op">)</span>, <span class="co"># The lower bounds for the values, note sigma (error), cannot be negative</span>
    method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,
    control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span>, <span class="co"># Indicates that the maximum is desired rather than the minimum</span>
    predictor <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>,
    outcome <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>
<span class="op">)</span></code></pre></div>
<p>We can get our results and compare them to the results of the <code>lm</code> function and find that they match to at least four decimal places.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.ll</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span></code></pre></div>
<pre><code><span class="co">## [1] 37.285114 -5.344468</span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm.out</span><span class="op">$</span><span class="va">coefficients</span></code></pre></div>
<pre><code><span class="co">## (Intercept)          wt </span>
<span class="co">##   37.285126   -5.344472</span></code></pre>
<p>Figure 8 shows the estimated regression line for each iteration of the optimization procedure (on the left; OLS regression line in blue; MLE regression line in black) with the estimated parameters and log-likelihood for all iterations on the left.</p>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-20-1.gif" alt="Figure 8. Animation of parameter estimates for each iteration of the optimization procedure."><p class="caption">
Figure 8. Animation of parameter estimates for each iteration of the optimization procedure.
</p>
</div>
<p>Figure 9 superimposes the normal distribution from which the log-likelihood is determined. The distribution is centered on <span class="math inline">\(\hat{y}\)</span>. The height of the distribution (i.e. density) at <span class="math inline">\(y\)</span> is the likelihood. We take the log of this value to get the log-likelihood. These log-likelihoods are calculated for each observation and summed. Maximum likelihood estimation is attempting to find the parameters (i.e. slope and intercept) that maximizes the log-likelihood.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">VisualStats</span><span class="fu">::</span><span class="fu"><a href="../reference/plot_likelihood.html">plot_likelihood</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span>, 
                           y <span class="op">=</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>,
                           pt <span class="op">=</span> <span class="fl">2</span>,
                           intercept <span class="op">=</span> <span class="va">optim.ll</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,
                           slope <span class="op">=</span> <span class="va">optim.ll</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,
                           sigma <span class="op">=</span> <span class="va">optim.ll</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-21-1.png" alt="Figure 9. Likelihood for one observeration superimposed on scatter plot." width="700"><p class="caption">
Figure 9. Likelihood for one observeration superimposed on scatter plot.
</p>
</div>
<p>Figure 10 depicts the likelihoods for the first 16 observations.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tmp</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">Iteration</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span>
<span class="va">plots</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">nplots</span> <span class="op">&lt;-</span> <span class="fl">16</span> <span class="co">#nrow(mtcars)</span>
<span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">nplots</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">a</span> <span class="op">&lt;-</span> <span class="va">tmp</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">$</span><span class="va">Intercept</span>
    <span class="va">b</span> <span class="op">&lt;-</span> <span class="va">tmp</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">$</span><span class="va">Slope</span>
    <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="va">tmp</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">$</span><span class="va">Sigma</span>
    <span class="va">predictor</span> <span class="op">&lt;-</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">wt</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>
    <span class="va">predicted.out</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span> <span class="op">*</span> <span class="va">predictor</span>
    <span class="va">outcome</span> <span class="op">&lt;-</span> <span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>
    <span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">outcome</span>, <span class="va">predicted.out</span>, <span class="va">sigma</span><span class="op">)</span>
    <span class="va">plots</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>,
                      n <span class="op">=</span> <span class="fl">101</span>,
                      args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="va">predicted.out</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu">annotate</span><span class="op">(</span>geom <span class="op">=</span> <span class="st">'segment'</span>, x <span class="op">=</span> <span class="va">outcome</span>, y <span class="op">=</span> <span class="fl">0</span>, xend <span class="op">=</span> <span class="va">outcome</span>, yend <span class="op">=</span> <span class="va">d</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu">annotate</span><span class="op">(</span>geom <span class="op">=</span> <span class="st">'point'</span>, x <span class="op">=</span> <span class="va">outcome</span>, y <span class="op">=</span> <span class="va">d</span>, color <span class="op">=</span> <span class="st">'red'</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu"><a href="https://rdrr.io/r/graphics/plot.window.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>, <span class="va">predicted.out</span> <span class="op">-</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">sigma</span><span class="op">)</span>,
               <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>, <span class="va">predicted.out</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu"><a href="https://rdrr.io/r/graphics/plot.window.html" class="external-link">ylim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
        <span class="fu">ylab</span><span class="op">(</span><span class="st">''</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlab</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/row.names.html" class="external-link">row.names</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>
<span class="op">}</span>
<span class="fu">plot_grid</span><span class="op">(</span>plotlist <span class="op">=</span> <span class="va">plots</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-22-1.png" alt="Figure 10. Likelihoods of the first 16 observations for the final parameter estimates." width="700"><p class="caption">
Figure 10. Likelihoods of the first 16 observations for the final parameter estimates.
</p>
</div>
<p>With MLE we need to estimate what is often referred to as the error term, or as we saw above is the standard deviation of the normal distribution from which we are estimating the likelihood from. In Figure 9 notice that the normal distribution id drawn vertically. This is because the likelihood is estimated from the error, or the residuals. In OLS we often report the root-mean-square deviation (RMSD, or root-mean-square error, RMSE). The RMSD is the standard deviation of the residuals:</p>
<p><span class="math display">\[RMSD\  =\  \sqrt{\frac{\sum^{N}_{i=1} (x_{i}-\hat{x_{i}} )^{2}}{N} }\]</span> Where <span class="math inline">\(i\)</span> is the observation, <span class="math inline">\(x_i\)</span> is the observed value, <span class="math inline">\(\hat{x_i}\)</span> is the estimated (predicted) value, and <span class="math inline">\(N\)</span> is the sample size. Below, we see that the numerical optimizer matches the RMSD within a rounding error.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.ll</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span></code></pre></div>
<pre><code><span class="co">## [1] 2.949164</span></code></pre>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html" class="external-link">resid</a></span><span class="op">(</span><span class="va">lm.out</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code><span class="co">## [1] 2.949163</span></code></pre>
</div>
<div class="section level2">
<h2 id="generalized-linear-models">Generalized Linear Models<a class="anchor" aria-label="anchor" href="#generalized-linear-models"></a>
</h2>
<p>Generalized linear models (GLM) are a generalization of OLS that allows for the response variables (i.e. dependent variables) to have an error distribution that is not distributed normally. All generalized linear models have the following three characteristics:</p>
<ol style="list-style-type: decimal">
<li>A probability distribution describing the outcome variable .</li>
<li>A linear model<br><span class="math inline">\(\eta = \beta_0+\beta_1 X_1 + \cdots + \beta_n X_n\)</span>.</li>
<li>A link function that relates the linear model to the parameter of the outcome distribution<br><span class="math inline">\(g(p) = \eta\)</span> or <span class="math inline">\(p = g^{-1}(\eta)\)</span>.</li>
</ol>
<p>We can estimate GLMs using MLE as described above. What will change is the log-likelihood function.</p>
</div>
<div class="section level2">
<h2 id="logistic-regression">Logistic Regression<a class="anchor" aria-label="anchor" href="#logistic-regression"></a>
</h2>
<p>Logistic regression is a GLM used to model a binary categorical variable using numerical and categorical predictors. We assume a binomial distribution produced the outcome variable and we therefore want to model <em>p</em> the probability of success for a given set of predictors. Instead of fitting a line (or a plane for two predictors, etc. for higher dimensions) we wish to fit the data to the logistic function which is defined as:</p>
<p><span class="math display">\[ \sigma \left( t \right) =\frac { { e }^{ t } }{ { e }^{ t }+1 } =\frac { 1 }{ 1+{ e }^{ -t } }  \]</span></p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">logistic</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">t</span><span class="op">)</span> <span class="op">{</span> 
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">t</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> 
<span class="op">}</span>
<span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">logistic</span>, n <span class="op">=</span> <span class="fl">101</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.window.html" class="external-link">xlim</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlab</span><span class="op">(</span><span class="st">'x'</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-24-1.png" alt="Figure 11. Logistic curve" width="700"><p class="caption">
Figure 11. Logistic curve
</p>
</div>
<p>To finish specifying the Logistic model we just need to establish a reasonable link function that connects <span class="math inline">\(\eta\)</span> to <span class="math inline">\(p\)</span>. There are a variety of options but the most commonly used is the logit function which is specified as:</p>
<p><span class="math display">\[logit(p) = \log\left(\frac{p}{1-p}\right),\text{ for $0\le p \le 1$}\]</span></p>
<p>We can specify <em>t</em> as a linear combination of our predictors (independent variables).</p>
<p><span class="math display">\[ t = \beta_0 + \beta_1 x \]</span></p>
<p>The logistic function can now be rewritten as:</p>
<p><span class="math display">\[ F\left( x \right) =\frac { 1 }{ 1+{ e }^{ -\left( { \beta  }_{ 0 }+\beta _{ 1 }x \right)  } } \]</span></p>
<p>Consider the following data set where we wish to predict whether a student will pass an exam based upon the number of hours they studied.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;These data were retrived from the &lt;a href="https://en.wikipedia.org/wiki/Logistic_regression" class="external-link"&gt;Wikipedia article on logistic regresion&lt;/a&gt;&lt;/p&gt;'><sup>2</sup></a>.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">study</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>
    Hours<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.50</span>,<span class="fl">0.75</span>,<span class="fl">1.00</span>,<span class="fl">1.25</span>,<span class="fl">1.50</span>,<span class="fl">1.75</span>,<span class="fl">1.75</span>,<span class="fl">2.00</span>,<span class="fl">2.25</span>,<span class="fl">2.50</span>,<span class="fl">2.75</span>,<span class="fl">3.00</span>,
            <span class="fl">3.25</span>,<span class="fl">3.50</span>,<span class="fl">4.00</span>,<span class="fl">4.25</span>,<span class="fl">4.50</span>,<span class="fl">4.75</span>,<span class="fl">5.00</span>,<span class="fl">5.50</span><span class="op">)</span>,
    Pass<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="mle_files/figure-html/unnamed-chunk-26-1.png" alt="Figure 12. Boxplot of hours studied by passing." width="700"><p class="caption">
Figure 12. Boxplot of hours studied by passing.
</p>
</div>
<p>First, we need to define logit function and the log-likelihood function that will be used by the <code>optim</code> function. Instead of using the normal distribution as above (using the <code>dnorm</code> function), we are using a binomial distribution and the logit to link the linear combination of predictors.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">logit</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">beta0</span>, <span class="va">beta1</span><span class="op">)</span> <span class="op">{</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">beta0</span> <span class="op">-</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span>
<span class="op">}</span>
<span class="va">loglikelihood.binomial</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">parameters</span>, <span class="va">predictor</span>, <span class="va">outcome</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">a</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="co"># Intercept</span>
    <span class="va">b</span> <span class="op">&lt;-</span> <span class="va">parameters</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="co"># beta coefficient</span>
    <span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/logit.html">logit</a></span><span class="op">(</span><span class="va">predictor</span>, <span class="va">a</span>, <span class="va">b</span><span class="op">)</span>
    <span class="va">ll</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span> <span class="va">outcome</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">outcome</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">ll</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Now we can call the <code>optim</code> function and get the final parameter estimates.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.binomial</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optim_save.html">optim_save</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="co"># Initial values</span>
    <span class="va">loglikelihood.binomial</span>,
    method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,
    control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span>,
    predictor <span class="op">=</span> <span class="va">study</span><span class="op">$</span><span class="va">Hours</span>,
    outcome <span class="op">=</span> <span class="va">study</span><span class="op">$</span><span class="va">Pass</span>
<span class="op">)</span></code></pre></div>
<p>In R, the <code>glm</code> (short for generalized linear models) function implements logistic regression when the <code>family = binomial(link = 'logit')</code> parameter is set. See <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">?glm</a></code> for other families of models to estimate models with other underlying distributions. We can see that our estimate matches the results of <code>glm</code> to a rounding error.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">optim.binomial</span><span class="op">$</span><span class="va">par</span></code></pre></div>
<pre><code><span class="co">## [1] -4.077575  1.504624</span></code></pre>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lr.out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">Pass</span> <span class="op">~</span> <span class="va">Hours</span>, data <span class="op">=</span> <span class="va">study</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">'logit'</span><span class="op">)</span><span class="op">)</span>
<span class="va">lr.out</span><span class="op">$</span><span class="va">coefficients</span></code></pre></div>
<pre><code><span class="co">## (Intercept)       Hours </span>
<span class="co">##   -4.077713    1.504645</span></code></pre>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Redefine the logistic function to include parameter estimates</span>
<span class="va">logistic</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">beta0</span>, <span class="va">beta1</span><span class="op">)</span> <span class="op">{</span>
    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span> <span class="op">*</span> <span class="op">(</span><span class="va">beta0</span> <span class="op">+</span> <span class="va">beta1</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">beta0</span> <span class="op">&lt;-</span> <span class="va">optim.binomial</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>
<span class="va">beta1</span> <span class="op">&lt;-</span> <span class="va">optim.binomial</span><span class="op">$</span><span class="va">par</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>

<span class="fu">ggplot</span><span class="op">(</span><span class="va">study</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Hours</span>, y <span class="op">=</span> <span class="va">Pass</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="../reference/logistic.html">logistic</a></span><span class="op">(</span><span class="va">Hours</span>, <span class="va">beta0</span>, <span class="va">beta1</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">logistic</span>, n <span class="op">=</span> <span class="fl">101</span>, 
                  args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>beta0 <span class="op">=</span> <span class="va">beta0</span>, beta1 <span class="op">=</span> <span class="va">beta1</span><span class="op">)</span> <span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_color_hue</span><span class="op">(</span><span class="st">'Predicted Pass &gt; 0.5'</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.85</span>, <span class="fl">0.15</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="mle_files/figure-html/unnamed-chunk-30-1.png" width="700" style="display: block; margin: auto;"></p>
<p>Let’s explore the process of the numeric optimizer. For this model, it took 70 iterations to converge to resulting parameters.</p>
<p><img src="mle_files/figure-html/unnamed-chunk-31-1.gif" style="display: block; margin: auto;"></p>
<p><img src="mle_files/figure-html/unnamed-chunk-32-1.png" width="700" style="display: block; margin: auto;"><img src="mle_files/figure-html/unnamed-chunk-32-2.png" width="700" style="display: block; margin: auto;"></p>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jason Bryer, Bruce Dudek.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
